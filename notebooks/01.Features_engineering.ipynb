{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.google.com/url?sa=i&url=https%3A%2F%2Faws.amazon.com%2Fes%2Fsolutions%2Fcase-studies%2FKueski%2F&psig=AOvVaw2G4P4XL7b6yQb4dv5CCv6i&ust=1640206653391000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCOjUsInk9fQCFQAAAAAdAAAAABAD\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue Job Preprocessing with PySpark-Kueski Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS Glue supports an extension of the PySpark Python dialect for scripting extract, transform, and load (ETL) jobs. In this notebook we use this dialect for creating an ETL script to run a Glue job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='contents' />\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. [Loading libraries](#loading)\n",
    "2. [Feature Engineering](#etl)\n",
    "3. [Writing results to S3](#s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading' />\n",
    "\n",
    "## 1. Loading libraries:\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>164</td><td>application_1622637872219_0164</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-32-171-232.ec2.internal:20888/proxy/application_1622637872219_0164/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-32-190-231.ec2.internal:8042/node/containerlogs/container_1622637872219_0164_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the required libraries"
     ]
    }
   ],
   "source": [
    "print('Loading the required libraries')\n",
    "import sys\n",
    "import pyspark.sql.functions as func\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "import json\n",
    "import boto3\n",
    "import ast\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import gc\n",
    "import sys\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "kms_key_id = '36f1041a-656a-4df4-954a-49b6a39e4b54'\n",
    "\n",
    "spark_conf = SparkConf().setAll([\n",
    "    (\"spark.hadoop.fs.s3.enableServerSideEncryption\", \"true\"),\n",
    "    (\"spark.hadoop.fs.s3.serverSideEncryption.kms.keyId\", kms_key_id),\n",
    "    (\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\"),\n",
    "    (\"hive.metastore.client.factory.class\", \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\"),\n",
    "    (\"spark.sql.catalogImplementation\", \"hive\"),\n",
    "    (\"hive.exec.dynamic.partition.mode\", \"nonstrict\")\n",
    "])\n",
    "sc = SparkContext.getOrCreate(conf=spark_conf)\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "logger = glueContext.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dejar variables del processing_job en el proceso.\n",
    "# Definir variable updated_at. ( podria ser una particion para quedarme solo con aquellas particiones que son las ultimas)\n",
    "# Primary key deberia ser el loan_id. Indice sobre el id del cliente.\n",
    "today       = datetime.strptime(\"2021-10-21\", '%Y-%m-%d').date()\n",
    "updated_at  = today.strftime('%Y-%m-%d')\n",
    "source_path =  \"s3://arcosmtk-working-directory/credits_scoring_test/dataset_credit_risk.csv.gz\"\n",
    "destination_path = \"s3://arcosmtk-working-directory/credits_scoring_test/offline_serving/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = glueContext.read.csv(source_path,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Formateo como fechas y ids. Deberia hacer QA por ejemplo fechas de laburo topearla a current date o cualquier otra estrategia.\n",
    "df = df.withColumn(\"id\", col('id').cast(IntegerType()))\n",
    "df = df.withColumn(\"loan_id\", col('loan_id').cast(IntegerType()))\n",
    "df = df.withColumn(\"loan_amount\", col('loan_amount').cast(DoubleType()))\n",
    "df = df.withColumn(\"loan_date\", to_date('loan_date','yyyy-MM-dd'))\n",
    "df = df.withColumn(\"job_start_date\", to_date('job_start_date','yyyy-MM-dd'))\n",
    "# skip OutOfBoundsError in to_timestamp function dont see here. QA \n",
    "df = df.withColumn(\"job_start_date\",when(col(\"job_start_date\") > current_date(),current_date()).otherwise(col('job_start_date')))\n",
    "df = df.withColumn(\"birthday\", to_date('birthday','yyyy-MM-dd'))\n",
    "# skip OutOfBoundsError in to_timestamp function dont see here. QA \n",
    "df = df.withColumn(\"birthday\",when(col(\"birthday\") > current_date(),current_date()).otherwise(col('birthday')))\n",
    "# La convierto a long para poder usar estrategia de ventaneo.\n",
    "df = df.withColumn(\"loan_date_ts\", unix_timestamp(to_timestamp(col('loan_date'),'yyyy-MM-dd')))\n",
    "# Declared processing_date.\n",
    "df = df.withColumn(\"processing_date\", lit(updated_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='etl' />\n",
    "\n",
    "## Featuring Engineering\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature nb_previous_loans\n",
    "df = df.withColumn(\"nb_previous_loans\", dense_rank().over(Window.partitionBy(\"id\").orderBy(asc(\"loan_date\")))-1)\n",
    "\n",
    "# avg_amount_loans_previous\n",
    "w = Window.partitionBy('id')\\\n",
    "                 .orderBy(asc('loan_date_ts'))\\\n",
    "                 .rangeBetween(Window.unboundedPreceding, -1)\n",
    "df = df.withColumn('avg_amount_loans_previous', mean('loan_amount').over(w))\n",
    "\n",
    "# Reproduccion de la variable age. #TODO aplicar control de calidad sobre la columna.\n",
    "df = df.withColumn(\"age\",(datediff(current_date(), col('birthday'))/365.25).cast(IntegerType()))\n",
    "\n",
    "# Ask DataScience better way to impute incorrect datos. For example bod or age > 100 years.\n",
    "df = df.withColumn(\"years_on_the_job\",(datediff(current_date(), col('job_start_date'))/365.25).cast(IntegerType()))\n",
    "\n",
    "# De nuevo no hay control de calidad sobre los datos de entrada. Convendria mejor un OneHOt Encoder.\n",
    "@udf(returnType=StringType()) \n",
    "def is_own_car(x):\n",
    "    return  0 if x == 'N' else 1\n",
    "df = df.withColumn(\"flag_own_car\",is_own_car(col(\"flag_own_car\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: integer (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- code_gender: string (nullable = true)\n",
      " |-- flag_own_car: string (nullable = true)\n",
      " |-- flag_own_realty: string (nullable = true)\n",
      " |-- cnt_children: string (nullable = true)\n",
      " |-- amt_income_total: string (nullable = true)\n",
      " |-- name_income_type: string (nullable = true)\n",
      " |-- name_education_type: string (nullable = true)\n",
      " |-- name_family_status: string (nullable = true)\n",
      " |-- name_housing_type: string (nullable = true)\n",
      " |-- days_birth: string (nullable = true)\n",
      " |-- days_employed: string (nullable = true)\n",
      " |-- flag_mobil: string (nullable = true)\n",
      " |-- flag_work_phone: string (nullable = true)\n",
      " |-- flag_phone: string (nullable = true)\n",
      " |-- flag_email: string (nullable = true)\n",
      " |-- occupation_type: string (nullable = true)\n",
      " |-- cnt_fam_members: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- birthday: date (nullable = true)\n",
      " |-- job_start_date: date (nullable = true)\n",
      " |-- loan_date: date (nullable = true)\n",
      " |-- loan_amount: double (nullable = true)\n",
      " |-- loan_date_ts: long (nullable = true)\n",
      " |-- processing_date: string (nullable = false)\n",
      " |-- nb_previous_loans: integer (nullable = true)\n",
      " |-- avg_amount_loans_previous: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- years_on_the_job: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(1978, 9, 10), datetime.date(2021, 12, 22))"
     ]
    }
   ],
   "source": [
    "df2.job_start_date.min(),df2.job_start_date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='etl' />\n",
    "\n",
    "## Writing results to S3\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardo en parquet (feature store offline) Discuss partitioning strategy. Take into account the refresh of old partitions\n",
    "# in prod enviromment. BE carefull by overwrite partitions. Need update parquet using upserts.\n",
    "#TODO change strategy to  \"feature online\" (SQL database) upsert records instead.\n",
    "df = df.repartition(\"loan_date\")\n",
    "df.write.mode('overwrite')\\\n",
    "        .format('parquet')\\\n",
    "        .partitionBy('loan_date')\\\n",
    "        .save(destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# online featute store replication\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
